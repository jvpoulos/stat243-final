{
    "contents" : "########################################\n## Rejection method: sampling N(0,1) draws\n## from double exponential distributions\n## with parameter alpha\n########################################\n\n## functional form of the double exponential\n\ndexp = function(x,mu=0,alpha=1){\n  (alpha/2.0)*exp(-alpha*abs(x-mu))\n}\n\nset.seed(12345)\n\n## generate N=5000 samples\n## from dexp(x, 1)\n## A Laplace (0, 1/alpha) can also be generated\n## as the difference of two i.i.d. Exponential(alpha) variates.\n\nn=5000\n\nrdoublexp <- function(n, alpha=1)\n{\n  exp1 <- rexp(n, alpha)\n  exp2 <- rexp(n, alpha)\n  out <- exp1-exp2\n  out\n}\n\n## step 1\n\ngdexp  <- rdoublexp(n) ## generate n samples from double exponential\ngunif <- runif(n) ## generate n samples from the unif[0,1]\n\n## step 2\n\n## Accept-reject step\n\nM <- sqrt(2*exp(1)/pi) ## constant\n\nweight <- dnorm(gdexp)/(M*dexp(gdexp, 0, 1))\n\n## determine which samples are accepted:\n\nind <- gunif<weight\naccepted <- gdexp[ind]\n\n## estimate of the prob. of acceptance\n\nfreq_accept <- length(accepted)/n\n\n## Plots\n\nx <- sort(accepted)\n\npar(mfrow=c(1,2))\nx0 <- seq(-6,6, by=0.1)\nhist(x,xlab=\"(a)\",ylab=\"\",prob=T, xlim=c(-4,4),breaks=25,main=\"histogram of accepted samples\")\nlines(x0,dnorm(x0), col=\"red\")\n\nplot(accepted, gunif[ind]*M*dexp(accepted), xlab=\"(b)\",ylab=\"\", main=\"accepted samples\",pch=20,cex=.3, col=\"sienna3\",)\nlines(x0,dnorm(x0), col=\"blue\") \n\n\n### ADAPTIVE REJECTION SAMPLING\n\n### Illustration by means of a Poisson regression example\n### (Adapted from Robert, Casella, 2005)\n\nsetwd(\"~/Lavoro/Teaching/SC/Classwork\")\n\n### Adaptive Rejection Sampling package\n### (Paulino Perez Rodriguez, original C++ code from Arnost Komarek based on ars.f written by P. Wild and W. R. Gilks)\n\ninstall.packages(\"ars\", lib=\"~/Lavoro/Rlibs\", repos=\"http://lib.stat.cmu.edu/R/CRAN\", destdir=\"~/Lavoro/Rlibs\", clean=TRUE)\n\n.libPaths(\"~/Lavoro/Rlibs\")\nlibrary(ars)\n\n## generates rvs from the loglinear posterior\n## This is the Prussian Horse kick data\n## data are the number of deaths in fourteen army corps\n## from 1875 to 1894\n## xdata = year; ydata=deaths from horse kicks\n\n\nxdata=c(75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94)\nydata=c(3,5,7,9,10,18,6,14,11,9,5,11,15,6,11,17,12,15,8,4)\n\nny<-length(ydata)\n\nB<-.025;s2<-5  #s2 is the prior variance of a\n\nSy<-sum(ydata)\n\n## The added constant makes exp(h) integrate to 1.\n## The log posterior - note that it is scaled by sum(exp(B*xdata)) - o.w.\n## the numbers are out of hand\n\n? ars\n\nh <-function(x){(x*Sy-exp(x)*sum(exp(B*xdata))-(x^2)/(2*s2))+166.4580696} \n\nhprima <- function(x){Sy-exp(x)*sum(exp(B*xdata))-x/s2}\n\nxbot<--0.15;xtop<-.5;steps<-.01\t\t\t\nx<-c(seq(xbot,xtop, by=steps))\t  #starting points\n\na <- ars(100000,h, hprima, x=c(1,-1,2), ub=1, xub=1) ## don't know why, it wants an upper bound\n\n## plot\n\npar(mfrow=c(1,1))\nytop<-6\nhist(a,xlim=c(xbot,xtop),freq=F,ylim=c(0,ytop),breaks=50,col=\"lightgrey\",xlab=\"\",ylab=\"\",main=\"\")\npar(new=T);\nplot(function(x)exp(h(x)),xlim=c(xbot,xtop),ylim=c(0,ytop),lwd=2,lty=1,ylab=\"\",xlab=\"\",main=\"\")\n\n\n#Example 2: sample 200 values from a gamma(2,0.5)\n\n\nf1<-function(x,shape,scale=1){(shape-1)*log(x)-x/scale}\nf1prima<-function(x,shape,scale=1) {(shape-1)/x-1/scale}\n\nmysample1<-ars(10000,f1,f1prima,x=4.5,m=1,lb=TRUE,xlb=0,shape=2,scale=0.5)\nhist(mysample1,freq=F,breaks=50,col=\"lightgrey\", xlim=c(0,5), ylim=c(0,1),  xlab=\"\",ylab=\"\",main=\"\")\npar(new=t);plot(function(mysample)dgamma(mysample,2,2.0),xlim=c(0,5), ylim=c(0,1), lwd=2,lty=1,ylab=\"\",xlab=\"\",main=\"\")\n\n\n\n### code proposed da Robert and Casella\n### for the Poisson Regression Example\n\n#generates rvs from the loglinear posterior\n#This is the Prussian Horse kick data\n#xdata = year; ydata=deaths from horse kicks\nxdata=c(75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94)\nydata=c(3,5,7,9,10,18,6,14,11,9,5,11,15,6,11,17,12,15,8,4)\nny<-length(ydata)\nSy<-sum(ydata);Sxy<-sum(xdata*ydata)\nB<-.025;s2<-5\t#s2 is the prior variance of a\n#The added constant makes exp(h) integrate to 1.\n#The log posterior - note that it is scaled by sum(exp(B*xdata)) - o.w.\nthe numbers are out of hand\nh<-function(x){(x*Sy-exp(x)*sum(exp(B*xdata))-(x^2)/(2*s2))+166.4580696} \n#---------------------------------------------------------------------------------------------------------------------------\n#-------------Begin the Simulation of g\n---------------------------------------------------------------------------\n  xbot<--.15;xtop<-.45;steps<-.01\t\t\t\nx<-c(seq(xbot,xtop, by=steps))\t\t\t#starting points\nnx<-length(x)\na<-array(0,c((nx-1),1));b<-array(0,c((nx-1),1))\t#arrays for the slope\nand intercept\nw<-array(0,c((nx-1),1))\t\t\t#array for weights\nfor(i in 1:(nx-1))\n{b[i]<-(h(x[i+1])-h(x[i]))/(x[i+1]-x[i]);a[i]<-h(x[i])-(b[i]*x[i])}\nfor(i in 2:(nx-2))\n{\n  temp<-(a[i-1]-a[i+1])/(b[i+1]-b[i])\n  temp1<-(exp(a[i-1])/b[i-1])*(exp(temp*b[i-1])-exp(b[i-1]*x[i]))\n  temp2<-(exp(a[i+1])/b[i+1])*(exp(b[i+1]*x[i+1])-exp(temp*b[i+1]))\n  temp3<-(exp(a[i-1])/b[i-1])*(exp(x[i+1]*b[i-1])-exp(b[i-1]*x[i]))\n  temp4<-(exp(a[i+1])/b[i+1])*(exp(b[i+1]*x[i+1])-exp(x[i]*b[i+1]))\n  w[i]<-temp1+temp2\n  if(temp<x[i])w[i]<-temp3\n  if(temp>x[i+1])w[i]<-temp4\n}\nw[1]<-(exp(a[2])/b[2])*(exp(b[2]*x[2])-exp(b[2]*x[1]))\t\t\t#endpoints\nw[nx-1]<-(exp(a[nx-1])/b[nx-1])*(exp(b[nx-1]*x[nx])-exp(b[nx-1]*x[nx-1]))\n#-----------------Generating\ng----------------------------------------------------------------------------\n  w<-w/sum(w)\nwt<- c(0,cumsum(w))\nnsim<-25000;xout<-array(0,c(nsim,1));hout<-array(0,c(nsim,1))\nfor(i in 1:nsim)\n{\n  u<-runif(1);ii<-sum(wt<u)\t#gives random index ii from 1 to nx-1\n  xout[i]<-x[ii]+u*(x[ii+1]-x[ii])\n  hout[i]<-h(xout[i])\n}\n#------------------Graphics--------------------------------------------------------------------------------------------------\n#plot(function(x)h(x))\nytop<-6\nhist(xout,xlim=c(xbot,xtop),freq=F,ylim=c(0,ytop),breaks=50,col=\"lightgrey\",xlab=\"\",ylab=\"\",main=\"\")\npar(new=T);plot(function(x)exp(h(x)),xlim=c(xbot,xtop),ylim=c(0,ytop),lwd=2,ylab=\"\",xlab=\"\",main=\"\")\ntext(.15,6,\"Histogram and Density of\")\ntext(.265,6,expression(g[n]))\n#Draws the g_n area picture\nxbot<-.1;xend<-.8;ybot<--.5;yend<-5;\nplot(function(x)exp(.75+1.5*x),xlim=c(xbot,xend),ylim=c(ybot,yend),tcl=NA,\n     xlab=\"\",ylab=\"\",xaxt=\"n\",yaxt=\"n\")\npolygon(x=c(xbot,xend),y=c(ybot,ybot),col=\"red\")\npolygon(x=c(.31,.31,.413,.541,.541),y=c(0,3.37,3.93,3.5,0),col=\"grey\")\npar(new=T);plot(function(x)exp(.75+1.5*x),xlim=c(xbot,xend),ylim=c(ybot,yend),\n                lwd=2,xlab=\"\",ylab=\"\",xaxt=\"n\",yaxt=\"n\")\npar(new=T);plot(function(x)exp(log(5.75)-log(2.5)*x),xlim=c(xbot,xend),ylim=c(ybot,yend),\n                lwd=2,xlab=\"\",ylab=\"\",xaxt=\"n\",yaxt=\"n\")\npar(new=T);plot(function(x)3.5*exp(-(x-.55)^2/1.5),xlim=c(xbot,xend),ylim=c(ybot,yend),\n                lwd=2,xlab=\"\",ylab=\"\",xaxt=\"n\",yaxt=\"n\")\nlines(x=c(.31,.31),y=c(0,3.37))\nlines(x=c(.54,.54),y=c(0,3.5))\nlines(x=c(.412,.412),y=c(0,3.94))\nlines(x=c(xbot,xend),y=c(0,0))\ntext(.7, 3.65,expression(f(x)))\ntext(.315, -.25,expression(x[2]))\ntext(.55, -.25,expression(x[3]))\ntext(.415, -.25,expression(frac(a[1]-a[3], b[3]-b[1])),cex=.85)\ntext(.275,4.75,expression(e^{a[1]+b[1]*x}))\ntext(.49,4.75,expression(e^{a[3]+b[3]*x}))",
    "created" : 1386212797910.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3772867201",
    "id" : "4D7756ED",
    "lastKnownWriteTime" : 1385527537,
    "path" : "~/Dropbox/stat243/final-project/ar2.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}